{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CeLEry Tutorial</center></h1>\n",
    "\n",
    "\n",
    "<center>Author: Qihuang Zhang*, Jian Hu, David Dai, Edward B. Lee, Rui Xiao, Mingyao Li*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. Installation\n",
    "2. Import modules\n",
    "3. Data Loading\n",
    "4. Run CeLEry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installation\n",
    "To install CeLEry package you must make sure that your python version is over 3.5.=. If you donâ€™t know the version of python you can check it by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Because CeLery depends on pytorch, you should make sure torch is correctly installed.\n",
    "<br>\n",
    "Now you can install the current release of CeLEry by the following three ways:\n",
    "#### 1.1 PyPI: Directly install the package from PyPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip3 install CeLEry\n",
    "#Note: you need to make sure that the pip is for python3, or we should install CeLEry by\n",
    "python3 -m pip install CeLEry\n",
    "pip3 install CeLEry\n",
    "#If you do not have permission (when you get a permission denied error), you should install CeLEry by\n",
    "pip3 install --user CeLEry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Github\n",
    "Download the package from Github and install it locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/QihuangZhang/CeLEry\n",
    "cd CeLEry/CeLEry_package/\n",
    "python3 setup.py install --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Anaconda\n",
    "If you do not have Python3.5 or Python3.6 installed, consider installing Anaconda (see Installing Anaconda). After installing Anaconda, you can create a new environment, for example, CeLEry (you can change to any name you like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an environment called CeLEry\n",
    "conda create -n CeLEry python=3.7.9\n",
    "#activate your environment \n",
    "conda activate CeLEry\n",
    "git clone https://github.com/QihuangZhang/CeLEry\n",
    "cd CeLEry/CeLEry_package/\n",
    "python3 setup.py build\n",
    "python3 setup.py install\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,csv,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import math\n",
    "from skimage import io, color\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "import random, torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "os.chdir(\"CeLEryPython\")\n",
    "import CeLEryPy as cel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cel.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read in data\n",
    "The current version of CeLEry takes two input data, the reference data and the query data. The reference data is used to trained the model and the query data is the dataset where predictions (or classifications) are made. \n",
    "<br>\n",
    "1. The Reference Data (the spatial transcriptomics data): AnnData format including   \n",
    "- the gene expression matrix spot by gene ($n_{spot}$ by $k$);\n",
    "- the spot-specific information (e.g., coordinates, layer, etc.)\n",
    "<br>\n",
    "2. The Query Data (the scRNA-seq data): AnnData format including \n",
    "- the gene expression matrix cell by gene ($n_{cell}$ by $k$);\n",
    "- the demographic information for each cell (e.g., cell type, layer, etc.)\n",
    "<br>\n",
    "\n",
    "AnnData stores a data matrix `.X` together with annotations of observations `.obs`, variables `.var` and unstructured annotations `.uns`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Read original 10x_h5 data and save it to h5ad\n",
    "from scanpy import read_10x_h5\n",
    "adata = read_10x_h5(\"../tutorial/data/151673/expression_matrix.h5\")\n",
    "spatial = pd.read_csv(\"../tutorial/data/151673/positions.txt\",sep=\",\",header=None,na_filter=False,index_col=0) \n",
    "adata.obs[\"x1\"] = spatial[1]\n",
    "adata.obs[\"x2\"] = spatial[2]\n",
    "adata.obs[\"x3\"] = spatial[3]\n",
    "adata.obs[\"x4\"] = spatial[4]\n",
    "adata.obs[\"x5\"] = spatial[5]\n",
    "adata.obs[\"x_array\"] = adata.obs[\"x2\"]\n",
    "adata.obs[\"y_array\"] = adata.obs[\"x3\"]\n",
    "adata.obs[\"x_pixel\"] = adata.obs[\"x4\"]\n",
    "adata.obs[\"y_pixel\"] = adata.obs[\"x5\"]\n",
    "#Select captured samples\n",
    "adata = adata[adata.obs[\"x1\"]==1]\n",
    "adata.var_names = [i.upper() for i in list(adata.var_names)]\n",
    "adata.var[\"genename\"] = adata.var.index.astype(\"str\")\n",
    "adata.write_h5ad(\"../tutorial/data/151673/sample_data.h5ad\")\n",
    "\"\"\"\n",
    "#Read in gene expression and spatial location\n",
    "Qdata = sc.read(\"../tutorial/data/MouseSCToy.h5ad\")\n",
    "Rdata = sc.read(\"../tutorial/data/MousePosteriorToy.h5ad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before inplementing our methods, we often normalize both the reference data and the query data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cel.get_zscore(Qdata)\n",
    "cel.get_zscore(Rdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run CeLEry\n",
    "\n",
    "We demonstrate the implemnetation of CeLEry in two tasks. In the first task, CeLEry is implemented to predict the 2D coordinates for the cells. In the second task, we classify the cells into different layers.\n",
    "\n",
    "#### 4.1 Analysis Task 1: Coordinates Recovery\n",
    "\n",
    "In the first task, we train a deep neural network using the reference data, and then apply the trained model to predict the location of the cells (or spots) in the query data. \n",
    "\n",
    "##### Training \n",
    "\n",
    "First, we train the model using spatial transcriptomic data. The trained model will also automately save as an ``.obj`` file in the specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_train = cel.Fit_cord (data_train = Rdata, hidden_dims = [30, 25, 15], num_epochs_max = 500, path = \"output/example\", filename = \"PreOrg_Mousesc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitting function ``Fit_cord`` involves the following parameters:\n",
    "\n",
    "- data_train (an annotated matrix): the input data\n",
    "\n",
    "- hidden_dims (a list of length three): the width of the neural network in each layer. In total, three layers are considered in the neural network.\n",
    "\n",
    "- num_epochs_max: maximum number of epochs considered in the training procedure. \n",
    "\n",
    "- path: the directory that saving the model object\n",
    "\n",
    "- filename: the name of the model object to be saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction \n",
    "\n",
    "Then, we apply the trained model to the query data to predict the coordinates of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cord = cel.Predict_cord (data_test = Qdata, path = \"output/example\", filename = \"PreOrg_Mousesc\")\n",
    "\n",
    "pred_cord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction function ``Predict_cord`` contains three arguments:\n",
    "- data_test (an annotated matrix): the input query dat\n",
    "\n",
    "- path: the directory that saving the model object\n",
    "\n",
    "- filename: the name of the model object to be saved\n",
    "\n",
    "\n",
    "The method implementation outputs the 2D coordinates in ``pred_cord``. A ``.csv`` file will also saved with the name \"predmatrix\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Analysis Task 2:  Layer Recovery\n",
    "\n",
    "In the second task, we use CeLEry to classify the cells into different layers. First, we load the spatial transcriptomics data with annotation for layers together with a single cell RNA data collected from an Alzheimer's study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdata = sc.read(\"../tutorial/data/AlzheimerToy.h5ad\")\n",
    "Rdata = sc.read(\"../tutorial/data/DataLayerToy.h5ad\")\n",
    "\n",
    "cel.get_zscore(Qdata)\n",
    "cel.get_zscore(Rdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample size of the spots in each layer could be very different, leading to the poor performance of the classification in some layers. We consider weighting the sample from each layer. A typical way to choose weight is to use $1/sample size$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_count =  Rdata.obs[\"Layer\"].value_counts().sort_index()\n",
    "layer_weight = layer_count[7]/layer_count[0:7]\n",
    "layer_weights = torch.tensor(layer_weight.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model using the function ``Fit_layer``. The model will returned and also save as an ``.obj`` object to be loaded later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = cel.Fit_layer (data_train = Rdata, layer_weights = layer_weights, layerkey = \"Layer\", hidden_dims = [30, 25, 15], num_epochs_max = 500, path = \"output/example\", filename = \"PreOrg_layer\")\n",
    "\n",
    "model_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred_cord = cel.Predict_cord (data_test = Qdata, path = \"output/example\", filename = \"PreOrg_Mousesc\")\n",
    "\n",
    "pred_cord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Augmentation\n",
    "Due to the limit sample size of the reference data (i.e, spatial transcriptomic data), we can also implementment an augmentation procedure to enlarge the sample size before implementing CeLEry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
